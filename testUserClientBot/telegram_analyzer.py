import asyncio
import json
import os
import re
from datetime import datetime
from typing import List, Dict, Set, Optional
from urllib.parse import urlparse

from pyrogram import Client
from pyrogram.types import Chat, Message, User
from pyrogram.errors import (
    ChannelPrivate, ChatAdminRequired, FloodWait, 
    UsernameNotOccupied, PeerIdInvalid
)
from dotenv import load_dotenv
import logging

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ
load_dotenv()

# ØªÙ†Ø¸ÛŒÙ… Ù„Ø§Ú¯
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TelegramAnalyzer:
    def __init__(self):
        # Ø®ÙˆØ§Ù†Ø¯Ù† ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø² ÙØ§ÛŒÙ„ .env
        self.api_id = int(os.getenv('API_ID'))
        self.api_hash = os.getenv('API_HASH')
        self.output_file = os.getenv('OUTPUT_FILE', 'my_chats.json')
        self.session_string = os.getenv('SESSION_STRING')
        
        # Ø§Ú¯Ø± SESSION_STRING Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ØŒ ÙˆÚ¯Ø±Ù†Ù‡ session Ø¬Ø¯ÛŒØ¯ Ø¨Ø³Ø§Ø²
        if self.session_string:
            self.app = Client(
                "telegram_analyzer",
                api_id=self.api_id,
                api_hash=self.api_hash,
                session_string=self.session_string
            )
        else:
            self.app = Client(
                "telegram_analyzer",
                api_id=self.api_id,
                api_hash=self.api_hash
            )
        
        # Ø§ÛŒØ¬Ø§Ø¯ ÙÙˆÙ„Ø¯Ø±Ù‡Ø§
        os.makedirs("results", exist_ok=True)
        os.makedirs("users", exist_ok=True)
        
        # Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡
        self.processed_users: Dict[int, Dict] = {}
        self.extracted_links: Set[str] = set()
        self.chat_analysis_results: List[Dict] = []

    def extract_links_from_text(self, text: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ø§Ø² Ù…ØªÙ†"""
        if not text:
            return []
            
        # Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ù„ÛŒÙ†Ú©
        patterns = [
            r'https?://[^\s<>"\']+',
            r'www\.[^\s<>"\']+',
            r't\.me/[^\s<>"\']+',
            r'@[a-zA-Z0-9_]+',
        ]
        
        links = []
        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            links.extend(matches)
        
        # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§
        cleaned_links = []
        for link in links:
            # Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ø§Ø² Ø§Ù†ØªÙ‡Ø§
            link = re.sub(r'[.,;:!?)\]}]+$', '', link)
            if link:
                cleaned_links.append(link)
        
        return cleaned_links

    async def analyze_chat_type(self, chat_link: str) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ù†ÙˆØ¹ Ú†Øª (Ú¯Ø±ÙˆÙ‡/Ú©Ø§Ù†Ø§Ù„ Ø¹Ù…ÙˆÙ…ÛŒ/Ø®ØµÙˆØµÛŒ)"""
        result = {
            "link": chat_link,
            "type": "unknown",
            "status": "unknown",
            "title": "",
            "username": "",
            "members_count": 0,
            "chat_id": None,
            "error": None
        }
        
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ username Ø§Ø² Ù„ÛŒÙ†Ú©
            username = chat_link.replace("https://t.me/", "").replace("@", "").split("?")[0].split("/")[0]
            
            chat = await self.app.get_chat(username)
            
            result["title"] = chat.title or ""
            result["username"] = chat.username or ""
            result["members_count"] = getattr(chat, 'members_count', 0)
            result["chat_id"] = chat.id
            
            if chat.type.name == "CHANNEL":
                result["type"] = "channel"
            elif chat.type.name in ["GROUP", "SUPERGROUP"]:
                result["type"] = "group"
            elif chat.type.name == "PRIVATE":
                result["type"] = "private"
            
            result["status"] = "public"
            
        except ChannelPrivate:
            result["status"] = "private"
            result["error"] = "Channel/Group is private"
        except (UsernameNotOccupied, PeerIdInvalid):
            result["error"] = "Invalid username or link"
        except Exception as e:
            result["error"] = str(e)
            logger.error(f"Error analyzing {chat_link}: {e}")
            
        return result

    async def process_user_message(self, message: Message, group_id: str, group_title: str = ""):
        """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø± Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª"""
        if not message.from_user:
            return
            
        user = message.from_user
        user_id = user.id
        
        # Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ø¬Ø¯ÛŒØ¯ Ø§Ø³ØªØŒ Ø§ÛŒØ¬Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯ Ø§ÙˆÙ„ÛŒÙ‡
        if user_id not in self.processed_users:
            self.processed_users[user_id] = {
                "user_id": user_id,
                "current_username": user.username,
                "current_name": f"{user.first_name or ''} {user.last_name or ''}".strip(),
                "username_history": [],
                "name_history": [],
                "is_bot": user.is_bot or False,
                "is_deleted": user.is_deleted or False,
                "joined_groups": [],
                "messages": []
            }
        
        user_data = self.processed_users[user_id]
        
        # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ username Ø§Ú¯Ø± ØªØºÛŒÛŒØ± Ú©Ø±Ø¯Ù‡
        if user.username and user.username != user_data["current_username"]:
            if user_data["current_username"]:
                user_data["username_history"].append({
                    "username": user_data["current_username"],
                    "changed_at": datetime.utcnow().isoformat()
                })
            user_data["current_username"] = user.username
        
        # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù†Ø§Ù… Ø§Ú¯Ø± ØªØºÛŒÛŒØ± Ú©Ø±Ø¯Ù‡
        current_name = f"{user.first_name or ''} {user.last_name or ''}".strip()
        if current_name and current_name != user_data["current_name"]:
            if user_data["current_name"]:
                user_data["name_history"].append({
                    "name": user_data["current_name"],
                    "changed_at": datetime.utcnow().isoformat()
                })
            user_data["current_name"] = current_name
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ú¯Ø±ÙˆÙ‡ Ø¨Ù‡ Ù„ÛŒØ³Øª Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø¶Ùˆ Ø´Ø¯Ù‡ (Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯)
        group_exists = any(g["group_id"] == group_id for g in user_data["joined_groups"])
        if not group_exists:
            user_data["joined_groups"].append({
                "group_id": group_id,
                "group_title": group_title,
                "joined_at": datetime.utcnow().isoformat(),
                "role": "member",
                "is_admin": False
            })
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù…
        reactions = []
        if hasattr(message, 'reactions') and message.reactions:
            for reaction in message.reactions.reactions:
                reactions.append(reaction.emoji)
        
        message_data = {
            "group_id": group_id,
            "message_id": message.id,
            "text": message.text or message.caption or "",
            "timestamp": message.date.isoformat() if message.date else datetime.utcnow().isoformat(),
            "reactions": reactions,
            "reply_to": message.reply_to_message_id,
            "edited": bool(message.edit_date),
            "is_forwarded": bool(message.forward_date)
        }
        
        user_data["messages"].append(message_data)

    async def analyze_chat_messages(self, chat_link: str, chat_info: Dict, limit: int = 1000):
        """ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ú†Øª Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§"""
        if chat_info["status"] != "public" or chat_info.get("error"):
            logger.warning(f"Skipping chat: {chat_link} - {chat_info.get('error', 'Private/Invalid')}")
            return
        
        try:
            chat_id = chat_info["chat_id"]
            chat_title = chat_info["title"]
            
            logger.info(f"ğŸ“¥ Analyzing messages in: {chat_title} (limit: {limit})")
            
            message_count = 0
            async for message in self.app.get_chat_history(chat_id, limit=limit):
                message_count += 1
                
                # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ø±Ø¨Ø± Ù¾ÛŒØ§Ù…
                await self.process_user_message(message, str(chat_id), chat_title)
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ø§Ø² Ù…ØªÙ† Ù¾ÛŒØ§Ù…
                text = message.text or message.caption or ""
                links = self.extract_links_from_text(text)
                
                for link in links:
                    self.extracted_links.add(link)
                
                # Ù„Ø§Ú¯ Ù¾ÛŒØ´Ø±ÙØª
                if message_count % 100 == 0:
                    logger.info(f"   ğŸ“Š Processed {message_count} messages...")
                    
                # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² flood
                await asyncio.sleep(0.05)
                
            logger.info(f"âœ… Completed: {message_count} messages from {chat_title}")
                
        except FloodWait as e:
            logger.warning(f"â³ FloodWait: sleeping for {e.value} seconds")
            await asyncio.sleep(e.value)
        except Exception as e:
            logger.error(f"âŒ Error analyzing chat {chat_link}: {e}")

    def save_results_to_files(self):
        """Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§"""
        logger.info("ğŸ’¾ Saving results to files...")
        
        # 1. Ø°Ø®ÛŒØ±Ù‡ ØªØ­Ù„ÛŒÙ„ Ú†Øªâ€ŒÙ‡Ø§
        with open("results/chat_analysis.json", "w", encoding="utf-8") as f:
            json.dump(self.chat_analysis_results, f, ensure_ascii=False, indent=2)
        
        # 2. Ø°Ø®ÛŒØ±Ù‡ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡
        with open("results/extracted_links.txt", "w", encoding="utf-8") as f:
            for link in sorted(self.extracted_links):
                f.write(f"{link}\n")
        
        # 3. Ø°Ø®ÛŒØ±Ù‡ ØªÙ…Ø§Ù… Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ JSON Ù‡Ù…
        with open("results/extracted_links.json", "w", encoding="utf-8") as f:
            json.dump(list(sorted(self.extracted_links)), f, ensure_ascii=False, indent=2)
        
        # 4. Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ JSON Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
        for user_id, user_data in self.processed_users.items():
            user_filename = f"users/user_{user_id}.json"
            
            with open(user_filename, "w", encoding="utf-8") as f:
                json.dump(user_data, f, ensure_ascii=False, indent=2)
        
        # 5. Ø°Ø®ÛŒØ±Ù‡ Ø®Ù„Ø§ØµÙ‡ Ú©Ù„ÛŒ
        summary = {
            "analysis_info": {
                "total_chats_analyzed": len(self.chat_analysis_results),
                "public_chats": len([c for c in self.chat_analysis_results if c["status"] == "public"]),
                "private_chats": len([c for c in self.chat_analysis_results if c["status"] == "private"]),
                "total_users": len(self.processed_users),
                "total_extracted_links": len(self.extracted_links),
                "analysis_date": datetime.utcnow().isoformat()
            },
            "chat_types": {
                "channels": len([c for c in self.chat_analysis_results if c["type"] == "channel"]),
                "groups": len([c for c in self.chat_analysis_results if c["type"] == "group"]),
                "unknown": len([c for c in self.chat_analysis_results if c["type"] == "unknown"])
            },
            "user_statistics": {}
        }
        
        # Ø¢Ù…Ø§Ø± Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
        for user_id, user_data in self.processed_users.items():
            summary["user_statistics"][str(user_id)] = {
                "username": user_data["current_username"],
                "name": user_data["current_name"],
                "total_messages": len(user_data["messages"]),
                "joined_groups_count": len(user_data["joined_groups"]),
                "is_bot": user_data["is_bot"]
            }
        
        # 6. Ø°Ø®ÛŒØ±Ù‡ Ø®Ù„Ø§ØµÙ‡ Ø¯Ø± ÙØ§ÛŒÙ„ ØªØ¹ÛŒÛŒÙ† Ø´Ø¯Ù‡ Ø¯Ø± .env
        with open(self.output_file, "w", encoding="utf-8") as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        with open("results/analysis_summary.json", "w", encoding="utf-8") as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        # 7. Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ
        logger.info("ğŸ“Š Analysis Results:")
        logger.info(f"   â€¢ Total chats: {len(self.chat_analysis_results)}")
        logger.info(f"   â€¢ Public chats: {summary['analysis_info']['public_chats']}")
        logger.info(f"   â€¢ Private chats: {summary['analysis_info']['private_chats']}")
        logger.info(f"   â€¢ Total users: {len(self.processed_users)}")
        logger.info(f"   â€¢ Extracted links: {len(self.extracted_links)}")
        logger.info(f"   â€¢ User files created: {len(self.processed_users)}")

    async def run_analysis(self, chat_links: List[str], messages_per_chat: int = 1000):
        """Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„"""
        async with self.app:
            logger.info("ğŸš€ Starting Telegram analysis...")
            logger.info(f"ğŸ“‹ Total links to analyze: {len(chat_links)}")
            
            # Ù…Ø±Ø­Ù„Ù‡ 1: ØªØ­Ù„ÛŒÙ„ Ù†ÙˆØ¹ Ú†Øªâ€ŒÙ‡Ø§
            logger.info("ğŸ” Phase 1: Analyzing chat types...")
            for i, link in enumerate(chat_links, 1):
                logger.info(f"   [{i}/{len(chat_links)}] {link}")
                result = await self.analyze_chat_type(link)
                self.chat_analysis_results.append(result)
                
                # Ø°Ø®ÛŒØ±Ù‡ ÙÙˆØ±ÛŒ Ù†ØªØ§ÛŒØ¬
                with open("results/chat_analysis.json", "w", encoding="utf-8") as f:
                    json.dump(self.chat_analysis_results, f, ensure_ascii=False, indent=2)
                
                await asyncio.sleep(1)  # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² flood
            
            # Ù…Ø±Ø­Ù„Ù‡ 2: ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§
            public_chats = [r for r in self.chat_analysis_results if r["status"] == "public"]
            logger.info(f"ğŸ“¥ Phase 2: Analyzing messages from {len(public_chats)} public chats...")
            
            for i, chat_info in enumerate(public_chats, 1):
                logger.info(f"   [{i}/{len(public_chats)}] Processing: {chat_info.get('title', chat_info['link'])}")
                await self.analyze_chat_messages(chat_info["link"], chat_info, messages_per_chat)
                
                # Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒØ§Ù†ÛŒ
                if i % 5 == 0:  # Ù‡Ø± 5 Ú†Øª ÛŒÚ©Ø¨Ø§Ø± Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†
                    logger.info("ğŸ’¾ Saving intermediate results...")
                    self.save_results_to_files()
            
            # Ù…Ø±Ø­Ù„Ù‡ 3: Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ
            logger.info("ğŸ’¾ Phase 3: Saving final results...")
            self.save_results_to_files()
            
            logger.info("âœ… Analysis completed successfully!")

def main():
    print("ğŸ¯ Telegram Channel/Group Analyzer v2.0")
    print("=" * 50)
    
    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„ .env
    if not os.path.exists('.env'):
        print("âŒ .env file not found!")
        print("Please create a .env file with your configuration.")
        return
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ø¶Ø±ÙˆØ±ÛŒ
    required_vars = ['API_ID', 'API_HASH']
    missing_vars = [var for var in required_vars if not os.getenv(var)]
    
    if missing_vars:
        print(f"âŒ Missing required environment variables: {', '.join(missing_vars)}")
        return
    
    # Ø®ÙˆØ§Ù†Ø¯Ù† Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§
    links_file = "links.txt"
    
    if os.path.exists(links_file):
        with open(links_file, "r", encoding="utf-8") as f:
            chat_links = [line.strip() for line in f if line.strip() and not line.startswith("#")]
    else:
        # Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ù†Ù…ÙˆÙ†Ù‡
        sample_links = [
            "# Add your Telegram links here (one per line)",
            "# Examples:",
            "# https://t.me/python",
            "# https://t.me/telegram",
            "# @channel_username",
            "",
            "https://t.me/python",
            "https://t.me/telegram"
        ]
        
        with open(links_file, "w", encoding="utf-8") as f:
            for link in sample_links:
                f.write(f"{link}\n")
        
        print(f"ğŸ“ Sample file '{links_file}' created.")
        print("Please add your Telegram links to this file and run the program again.")
        return
    
    if not chat_links:
        print("âŒ No links found in links.txt!")
        return
    
    print(f"ğŸ“‹ Found {len(chat_links)} links to analyze")
    
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª
    try:
        messages_limit = int(input("Enter messages limit per chat (default 1000): ").strip() or "1000")
    except ValueError:
        messages_limit = 1000
    
    # ØªØ§ÛŒÛŒØ¯ Ø§Ø² Ú©Ø§Ø±Ø¨Ø±
    print(f"\nğŸ“Š Analysis Settings:")
    print(f"   â€¢ Total links: {len(chat_links)}")
    print(f"   â€¢ Messages per chat: {messages_limit}")
    print(f"   â€¢ Output file: {os.getenv('OUTPUT_FILE', 'my_chats.json')}")
    
    response = input("\nDo you want to continue? (y/n): ").strip().lower()
    if response != 'y':
        print("âŒ Operation cancelled.")
        return
    
    # Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
    analyzer = TelegramAnalyzer()
    try:
        asyncio.run(analyzer.run_analysis(chat_links, messages_limit))
        
        print("\nğŸ‰ Analysis completed successfully!")
        print(f"ğŸ“ Results saved in:")
        print(f"   â€¢ {analyzer.output_file} (Main output)")
        print(f"   â€¢ results/chat_analysis.json (Chat analysis)")
        print(f"   â€¢ results/extracted_links.txt (Extracted links)")
        print(f"   â€¢ results/analysis_summary.json (Detailed summary)")
        print(f"   â€¢ users/ directory (Individual user files)")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Analysis stopped by user")
        # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¬Ø²Ø¦ÛŒ
        analyzer.save_results_to_files()
        print("ğŸ’¾ Partial results saved.")
    except Exception as e:
        print(f"\nâŒ Error occurred: {e}")
        logger.exception("Full error details:")

if __name__ == "__main__":
    main()
