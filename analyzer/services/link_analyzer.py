import re
from typing import Dict, List, Optional
from urllib.parse import urlparse, parse_qs, unquote

from models.data_models import LinkInfo
from utils.logger import logger

class LinkAnalyzer:
    """Ú©Ù„Ø§Ø³ ØªØ­Ù„ÛŒÙ„ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§"""
    
    def __init__(self):
        self.redirect_mapping: Dict[str, str] = {}
    
    def extract_telegram_link_from_redirect(self, redirect_url: str) -> Optional[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú© ØªÙ„Ú¯Ø±Ø§Ù… Ø§ØµÙ„ÛŒ Ø§Ø² Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ø±ÛŒØ¯Ø§ÛŒØ±Ú©Øª"""
        try:
            # Google Translate links
            if 'translate.google.com' in redirect_url:
                parsed = urlparse(redirect_url)
                params = parse_qs(parsed.query)
                
                if 'u' in params:
                    original_url = unquote(params['u'][0])
                    if 't.me' in original_url:
                        return original_url
            
            # Ø³Ø§ÛŒØ± Ø§Ù†ÙˆØ§Ø¹ Ø±ÛŒØ¯Ø§ÛŒØ±Ú©Øªâ€ŒÙ‡Ø§
            # Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§ÛŒÙ†Ø¬Ø§ Ø§Ù†ÙˆØ§Ø¹ Ø¯ÛŒÚ¯Ø± Ø±ÛŒØ¯Ø§ÛŒØ±Ú©Øª Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯
            
            return None
        except Exception as e:
            logger.error(f"Error extracting from redirect {redirect_url}: {e}")
            return None
    
    async def resolve_redirect_links(self, links: List[str]) -> List[str]:
        """Ø­Ù„ Ú©Ø±Ø¯Ù† Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ø±ÛŒØ¯Ø§ÛŒØ±Ú©Øª Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ"""
        resolved_links = []
        
        for link in links:
            if 't.me' in link and 'translate.google.com' not in link:
                # Ù„ÛŒÙ†Ú© Ù…Ø³ØªÙ‚ÛŒÙ… ØªÙ„Ú¯Ø±Ø§Ù…
                resolved_links.append(link)
                continue
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ø§ÛŒÙ† ÛŒÚ© Ù„ÛŒÙ†Ú© Ø±ÛŒØ¯Ø§ÛŒØ±Ú©Øª Ø§Ø³Øª
            extracted_link = self.extract_telegram_link_from_redirect(link)
            if extracted_link:
                logger.info(f"ğŸ”— Redirect resolved: {link[:50]}... -> {extracted_link}")
                self.redirect_mapping[link] = extracted_link
                resolved_links.append(extracted_link)
            else:
                # Ø§Ú¯Ø± Ù†ØªÙˆØ§Ù†Ø³ØªÛŒÙ… Ù„ÛŒÙ†Ú© Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†ÛŒÙ…ØŒ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† invalid Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ…
                logger.warning(f"âš ï¸ Could not resolve redirect: {link[:100]}...")
                resolved_links.append(link)  # Ø¨Ø±Ø§ÛŒ tracking
        
        return resolved_links
    
    def categorize_telegram_link(self, link: str) -> LinkInfo:
        """Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù…"""
        link_info = LinkInfo(
            original_link=link,
            type="unknown",
            identifier="",
            is_invite_link=False,
            is_redirect=False
        )
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø±ÛŒØ¯Ø§ÛŒØ±Ú©Øª
        if link in self.redirect_mapping:
            link_info.is_redirect = True
            link_info.redirect_source = link
            link = self.redirect_mapping[link]  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù„ÛŒÙ†Ú© Ø§ØµÙ„ÛŒ
        
        if not 't.me' in link:
            link_info.type = "invalid"
            return link_info
        
        try:
            # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù„ÛŒÙ†Ú©
            clean_link = link.split('?')[0]  # Ø­Ø°Ù query parameters
            
            if '/joinchat/' in clean_link:
                # Ù„ÛŒÙ†Ú© Ø¯Ø¹ÙˆØª
                link_info.type = "invite_link"
                link_info.is_invite_link = True
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ invite hash
                hash_part = clean_link.split('/joinchat/')[-1]
                link_info.identifier = hash_part
                
            elif '/+' in clean_link:
                # ÙØ±Ù…Øª Ø¬Ø¯ÛŒØ¯ Ù„ÛŒÙ†Ú© Ø¯Ø¹ÙˆØª
                link_info.type = "invite_link"
                link_info.is_invite_link = True
                hash_part = clean_link.split('/+')[-1]
                link_info.identifier = hash_part
                
            else:
                # Ù„ÛŒÙ†Ú© Ø¹Ù…ÙˆÙ…ÛŒ Ø¨Ø§ username
                link_info.type = "public_link"
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ username
                username = clean_link.replace("https://t.me/", "").replace("@", "")
                if '/' in username:
                    username = username.split('/')[0]
                link_info.identifier = username
                
        except Exception as e:
            logger.error(f"Error categorizing link {link}: {e}")
            link_info.type = "invalid"
        
        return link_info
    
    def extract_links_from_text(self, text: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ø§Ø² Ù…ØªÙ†"""
        if not text:
            return []
            
        # Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ù„ÛŒÙ†Ú©
        patterns = [
            r'https?://[^\s<>"\']+',
            r'www\.[^\s<>"\']+',
            r't\.me/[^\s<>"\']+',
            r'@[a-zA-Z0-9_]+',
        ]
        
        links = []
        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            links.extend(matches)
        
        # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§
        cleaned_links = []
        for link in links:
            # Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ø§Ø² Ø§Ù†ØªÙ‡Ø§
            link = re.sub(r'[.,;:!?)\\]}]+$', '', link)
            if link:
                cleaned_links.append(link)
        
        return cleaned_links
