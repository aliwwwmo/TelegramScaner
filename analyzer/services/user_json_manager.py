import json
import os
import asyncio
import re
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple
from pyrogram import Client
from pyrogram.errors import FloodWait, RPCError
from config.settings import TELEGRAM_CONFIG
from utils.logger import logger

class UserJSONManager:
    """Ù…Ø¯ÛŒØ±ÛŒØª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ JSON Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø§Ø² Saved Messages"""
    
    def __init__(self):
        self.api_id = TELEGRAM_CONFIG.api_id
        self.api_hash = TELEGRAM_CONFIG.api_hash
        self.session_string = TELEGRAM_CONFIG.session_string
        self.client = None
        
    async def __aenter__(self):
        """Ø´Ø±ÙˆØ¹ Ú©Ù„Ø§ÛŒÙ†Øª ØªÙ„Ú¯Ø±Ø§Ù…"""
        try:
            self.client = Client(
                "user_json_manager",
                api_id=self.api_id,
                api_hash=self.api_hash,
                session_string=self.session_string
            )
            await self.client.start()
            
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Saved Messages
            me = await self.client.get_me()
            self.target_chat_id = me.id
            logger.info(f"âœ… Connected to Saved Messages (ID: {self.target_chat_id})")
            
            return self
        except Exception as e:
            logger.error(f"âŒ Failed to start Telegram client: {e}")
            raise
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ØªÙˆÙ‚Ù Ú©Ù„Ø§ÛŒÙ†Øª ØªÙ„Ú¯Ø±Ø§Ù…"""
        if self.client:
            await self.client.stop()
            logger.info("ğŸ›‘ Telegram client stopped")
    
    def extract_user_id_from_filename(self, filename: str) -> Optional[int]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ user_id Ø§Ø² Ù†Ø§Ù… ÙØ§ÛŒÙ„"""
        try:
            # Ø§Ù„Ú¯ÙˆÛŒ Ø³Ø§Ø¯Ù‡â€ŒØªØ± Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
            patterns = [
                # Ø§Ù„Ú¯ÙˆÛŒ Ø§ØµÙ„ÛŒ: temp_user_id_group_id_timestamp_uuid.json
                r'^temp_(\d+)_[^_]+_\d{8}_\d{6}_[a-f0-9]{8}\.json$',
                # Ø§Ù„Ú¯ÙˆÛŒ Ø¨Ø§ group_id Ù…Ù†ÙÛŒ: temp_user_id_-group_id_timestamp_uuid.json
                r'^temp_(\d+)_-?\d+_\d{8}_\d{6}_[a-f0-9]{8}\.json$',
                # Ø§Ù„Ú¯ÙˆÛŒ Ø¨Ø¯ÙˆÙ† temp_: user_id_group_id_timestamp_uuid.json
                r'^(\d+)_[^_]+_\d{8}_\d{6}_[a-f0-9]{8}\.json$',
                # Ø§Ù„Ú¯ÙˆÛŒ Ø¨Ø¯ÙˆÙ† temp_ Ùˆ group_id Ù…Ù†ÙÛŒ: user_id_-group_id_timestamp_uuid.json
                r'^(\d+)_-?\d+_\d{8}_\d{6}_[a-f0-9]{8}\.json$',
                # Ø§Ù„Ú¯ÙˆÛŒ Ø¹Ù…ÙˆÙ…ÛŒâ€ŒØªØ±: Ù‡Ø± ÙØ§ÛŒÙ„ÛŒ Ú©Ù‡ Ø¨Ø§ temp_ Ø´Ø±ÙˆØ¹ Ø´ÙˆØ¯ Ùˆ user_id Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
                r'^temp_(\d+)_[^_]*\.json$',
                # Ø§Ù„Ú¯ÙˆÛŒ Ø¹Ù…ÙˆÙ…ÛŒâ€ŒØªØ±: Ù‡Ø± ÙØ§ÛŒÙ„ÛŒ Ú©Ù‡ user_id Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
                r'^(\d+)_[^_]*\.json$',
                # Ø§Ù„Ú¯ÙˆÛŒ Ø®ÛŒÙ„ÛŒ Ø³Ø§Ø¯Ù‡: Ù‡Ø± ÙØ§ÛŒÙ„ÛŒ Ú©Ù‡ Ø¨Ø§ temp_ Ø´Ø±ÙˆØ¹ Ø´ÙˆØ¯ Ùˆ Ø¹Ø¯Ø¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
                r'^temp_(\d+)_.*\.json$',
                # Ø§Ù„Ú¯ÙˆÛŒ Ø®ÛŒÙ„ÛŒ Ø³Ø§Ø¯Ù‡: Ù‡Ø± ÙØ§ÛŒÙ„ÛŒ Ú©Ù‡ Ø¨Ø§ Ø¹Ø¯Ø¯ Ø´Ø±ÙˆØ¹ Ø´ÙˆØ¯
                r'^(\d+)_.*\.json$'
            ]
            
            for pattern in patterns:
                match = re.match(pattern, filename)
                if match:
                    user_id = int(match.group(1))
                    logger.info(f"âœ… Extracted user_id {user_id} from {filename} using pattern: {pattern}")
                    return user_id
            
            logger.info(f"âŒ No pattern matched for filename: {filename}")
            return None
        except Exception as e:
            logger.error(f"âŒ Error extracting user_id from filename {filename}: {e}")
            return None
    
    def extract_timestamp_from_filename(self, filename: str) -> Optional[datetime]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ timestamp Ø§Ø² Ù†Ø§Ù… ÙØ§ÛŒÙ„"""
        try:
            # Ø§Ù„Ú¯ÙˆÛŒ Ø³Ø§Ø¯Ù‡â€ŒØªØ± Ø¨Ø±Ø§ÛŒ timestamp
            patterns = [
                # Ø§Ù„Ú¯ÙˆÛŒ Ø§ØµÙ„ÛŒ: temp_user_id_group_id_YYYYMMDD_HHMMSS_uuid.json
                r'^temp_\d+_[^_]+_(\d{8}_\d{6})_[a-f0-9]{8}\.json$',
                # Ø§Ù„Ú¯ÙˆÛŒ Ø¨Ø§ group_id Ù…Ù†ÙÛŒ: temp_user_id_-group_id_YYYYMMDD_HHMMSS_uuid.json
                r'^temp_\d+_-?\d+_(\d{8}_\d{6})_[a-f0-9]{8}\.json$',
                # Ø§Ù„Ú¯ÙˆÛŒ Ø¨Ø¯ÙˆÙ† temp_: user_id_group_id_YYYYMMDD_HHMMSS_uuid.json
                r'^\d+_[^_]+_(\d{8}_\d{6})_[a-f0-9]{8}\.json$',
                # Ø§Ù„Ú¯ÙˆÛŒ Ø¨Ø¯ÙˆÙ† temp_ Ùˆ group_id Ù…Ù†ÙÛŒ: user_id_-group_id_YYYYMMDD_HHMMSS_uuid.json
                r'^\d+_-?\d+_(\d{8}_\d{6})_[a-f0-9]{8}\.json$',
                # Ø§Ù„Ú¯ÙˆÛŒ Ø¹Ù…ÙˆÙ…ÛŒâ€ŒØªØ±: Ù‡Ø± ÙØ§ÛŒÙ„ÛŒ Ú©Ù‡ timestamp Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
                r'.*_(\d{8}_\d{6})_[a-f0-9]{8}\.json$'
            ]
            
            for pattern in patterns:
                match = re.match(pattern, filename)
                if match:
                    timestamp_str = match.group(1)
                    try:
                        return datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')
                    except ValueError:
                        logger.debug(f"âŒ Invalid timestamp format: {timestamp_str}")
                        continue
            
            logger.debug(f"âŒ No timestamp found in filename: {filename}")
            return None
        except Exception as e:
            logger.error(f"âŒ Error extracting timestamp from filename {filename}: {e}")
            return None
    
    async def get_user_json_files(self, user_id: int) -> List[Dict[str, Any]]:
        """Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ JSON Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ ÛŒÚ© Ú©Ø§Ø±Ø¨Ø±"""
        try:
            user_files = []
            all_files = []
            
            # Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø§Ù… Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Saved Messages
            async for message in self.client.get_chat_history(self.target_chat_id, limit=1000):
                try:
                    # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ù¾ÛŒØ§Ù… Ø´Ø§Ù…Ù„ ÙØ§ÛŒÙ„ Ø§Ø³Øª
                    if message.document and message.document.file_name:
                        filename = message.document.file_name
                        all_files.append(filename)
                        
                        # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ ÙØ§ÛŒÙ„ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø± Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø§Ø³Øª
                        file_user_id = self.extract_user_id_from_filename(filename)
                        if file_user_id == user_id:
                            file_info = {
                                'message_id': message.id,
                                'filename': filename,
                                'file_id': message.document.file_id,
                                'file_size': message.document.file_size,
                                'timestamp': self.extract_timestamp_from_filename(filename),
                                'date': message.date,
                                'caption': None  # Ø­Ø°Ù caption Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§
                            }
                            user_files.append(file_info)
                except Exception as e:
                    logger.warning(f"âš ï¸ Error processing message: {e}")
                    continue
            
            # Ù…Ø±ØªØ¨ Ú©Ø±Ø¯Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ timestamp
            user_files.sort(key=lambda x: x['timestamp'] if x['timestamp'] else datetime.min)
            
            logger.info(f"âœ… Found {len(user_files)} JSON files for user {user_id}")
            
            # Ù†Ù…Ø§ÛŒØ´ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ JSON Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø±Ø§ÛŒ debug
            json_files = [f for f in all_files if f.endswith('.json')]
            logger.info(f"ğŸ“ Total JSON files found: {len(json_files)}")
            if json_files:
                logger.info("ğŸ“‹ Sample JSON files:")
                for filename in json_files[:5]:  # Ù†Ù…Ø§ÛŒØ´ 5 ÙØ§ÛŒÙ„ Ø§ÙˆÙ„
                    extracted_id = self.extract_user_id_from_filename(filename)
                    logger.info(f"   - {filename} (extracted user_id: {extracted_id})")
            
            return user_files
            
        except Exception as e:
            import traceback
            logger.error(f"âŒ Error getting user JSON files: {e}")
            logger.error(f"âŒ Traceback: {traceback.format_exc()}")
            return []
    
    async def download_and_parse_json(self, file_id: str) -> Optional[Dict[str, Any]]:
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„ JSON"""
        try:
            # Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„
            temp_file = await self.client.download_media(file_id)
            
            if not temp_file or not os.path.exists(temp_file):
                logger.error(f"âŒ Failed to download file: {file_id}")
                return None
            
            # Ø®ÙˆØ§Ù†Ø¯Ù† Ùˆ Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† JSON
            with open(temp_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # Ø­Ø°Ù ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª
            os.remove(temp_file)
            
            return data
            
        except Exception as e:
            logger.error(f"âŒ Error downloading/parsing JSON file: {e}")
            return None
    
    async def merge_user_json_files(self, user_id: int) -> Tuple[bool, Optional[Dict[str, Any]], Optional[str]]:
        """ØªØ±Ú©ÛŒØ¨ ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ JSON ÛŒÚ© Ú©Ø§Ø±Ø¨Ø±"""
        try:
            # Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±
            user_files = await self.get_user_json_files(user_id)
            
            if not user_files:
                logger.warning(f"âš ï¸ No JSON files found for user {user_id}")
                return False, None, None
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ù‚Ø¨Ù„Ø§Ù‹ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
            final_filename = None
            final_file_data = None
            
            # Ø¬Ø³ØªØ¬ÙˆÛŒ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ (Ø¨Ø§ Ù¾ÛŒØ´ÙˆÙ†Ø¯ final_)
            for file_info in user_files:
                if file_info['filename'].startswith(f'final_{user_id}_'):
                    final_filename = file_info['filename']
                    final_file_data = await self.download_and_parse_json(file_info['file_id'])
                    break
            
            # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
            if final_file_data:
                final_timestamp = self.extract_timestamp_from_filename(final_filename)
                new_files = []
                
                for file_info in user_files:
                    if not file_info['filename'].startswith('final_'):
                        file_timestamp = file_info['timestamp']
                        if file_timestamp and file_timestamp > final_timestamp:
                            new_files.append(file_info)
                
                if not new_files:
                    logger.info(f"âœ… No new files found for user {user_id}, returning existing final file")
                    return True, final_file_data, final_filename
                
                # ØªØ±Ú©ÛŒØ¨ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
                merged_data = final_file_data.copy()
                merged_messages = merged_data.get('messages', [])
                
                for file_info in new_files:
                    file_data = await self.download_and_parse_json(file_info['file_id'])
                    if file_data:
                        new_messages = file_data.get('messages', [])
                        merged_messages.extend(new_messages)
                
                merged_data['messages'] = merged_messages
                merged_data['total_files_merged'] = len(new_files) + 1
                merged_data['last_merge_date'] = datetime.now().isoformat()
                
            else:
                # ØªØ±Ú©ÛŒØ¨ ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
                merged_data = {
                    'user_id': user_id,
                    'merge_date': datetime.now().isoformat(),
                    'total_files_merged': len(user_files),
                    'messages': [],
                    'user_info': {},
                    'groups_info': []
                }
                
                # Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªÚ©Ø±Ø§Ø± Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§
                seen_message_ids = set()
                user_info_found = False
                groups_info = {}
                
                # Ø¨Ø±Ø§ÛŒ ØªØ±Ú©ÛŒØ¨ ØªØ§Ø±ÛŒØ®Ú†Ù‡ username Ùˆ name
                username_history = {}
                name_history = {}
                
                processed_files = 0
                for file_info in user_files:
                    # Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ (Ù†Ù‡ ÙÙ‚Ø· ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ final_)
                    file_data = await self.download_and_parse_json(file_info['file_id'])
                    if file_data:
                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±
                        if not user_info_found and 'current_username' in file_data:
                            merged_data['user_info'] = {
                                'current_username': file_data.get('current_username'),
                                'current_name': file_data.get('current_name'),
                                'username_history': file_data.get('username_history', []),
                                'name_history': file_data.get('name_history', []),
                                'is_bot': file_data.get('is_bot', False),
                                'is_deleted': file_data.get('is_deleted', False),
                                'is_verified': file_data.get('is_verified', False),
                                'is_premium': file_data.get('is_premium', False),
                                'is_scam': file_data.get('is_scam', False),
                                'is_fake': file_data.get('is_fake', False),
                                'phone_number': file_data.get('phone_number'),
                                'language_code': file_data.get('language_code'),
                                'dc_id': file_data.get('dc_id'),
                                'first_seen': file_data.get('first_seen'),
                                'last_seen': file_data.get('last_seen')
                            }
                            user_info_found = True
                            logger.info(f"ğŸ“‹ Found user info: {file_data.get('current_username', 'unknown')}")
                        
                        # ØªØ±Ú©ÛŒØ¨ ØªØ§Ø±ÛŒØ®Ú†Ù‡ username
                        if 'username_history' in file_data:
                            for username_entry in file_data['username_history']:
                                username = username_entry.get('username')
                                changed_at = username_entry.get('changed_at')
                                if username and changed_at:
                                    if username not in username_history or changed_at > username_history[username]:
                                        username_history[username] = changed_at
                        
                        # ØªØ±Ú©ÛŒØ¨ ØªØ§Ø±ÛŒØ®Ú†Ù‡ name
                        if 'name_history' in file_data:
                            for name_entry in file_data['name_history']:
                                name = name_entry.get('name')
                                changed_at = name_entry.get('changed_at')
                                if name and changed_at:
                                    if name not in name_history or changed_at > name_history[name]:
                                        name_history[name] = changed_at
                        
                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú¯Ø±ÙˆÙ‡
                        if 'group_info' in file_data:
                            group_info = file_data['group_info']
                            group_id = group_info.get('group_id')
                            if group_id and group_id not in groups_info:
                                groups_info[group_id] = group_info
                                logger.info(f"ğŸ“ Found group info: {group_info.get('group_title', 'unknown')}")
                        
                        # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ø¨Ø¯ÙˆÙ† ØªÚ©Ø±Ø§Ø±
                        messages_to_add = []
                        if 'messages' in file_data:
                            messages = file_data.get('messages', [])
                        elif 'messages_in_this_group' in file_data:
                            messages = file_data.get('messages_in_this_group', [])
                        else:
                            messages = []
                        
                        for message in messages:
                            message_id = message.get('message_id')
                            if message_id and message_id not in seen_message_ids:
                                seen_message_ids.add(message_id)
                                messages_to_add.append(message)
                        
                        merged_data['messages'].extend(messages_to_add)
                        logger.info(f"ğŸ“„ Added {len(messages_to_add)} unique messages from {file_info['filename']}")
                        processed_files += 1
                
                # ØªØ¨Ø¯ÛŒÙ„ groups_info Ø¨Ù‡ Ù„ÛŒØ³Øª
                merged_data['groups_info'] = list(groups_info.values())
                
                # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡â€ŒÙ‡Ø§ Ø¯Ø± user_info
                if merged_data['user_info']:
                    # ØªØ¨Ø¯ÛŒÙ„ username_history Ø¨Ù‡ Ù„ÛŒØ³Øª
                    username_history_list = []
                    for username, changed_at in username_history.items():
                        username_history_list.append({
                            'username': username,
                            'changed_at': changed_at
                        })
                    # Ù…Ø±ØªØ¨ Ú©Ø±Ø¯Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ§Ø±ÛŒØ®
                    username_history_list.sort(key=lambda x: x['changed_at'])
                    merged_data['user_info']['username_history'] = username_history_list
                    
                    # ØªØ¨Ø¯ÛŒÙ„ name_history Ø¨Ù‡ Ù„ÛŒØ³Øª
                    name_history_list = []
                    for name, changed_at in name_history.items():
                        name_history_list.append({
                            'name': name,
                            'changed_at': changed_at
                        })
                    # Ù…Ø±ØªØ¨ Ú©Ø±Ø¯Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ§Ø±ÛŒØ®
                    name_history_list.sort(key=lambda x: x['changed_at'])
                    merged_data['user_info']['name_history'] = name_history_list
                    
                    logger.info(f"ğŸ“‹ Combined username history: {len(username_history_list)} entries")
                    logger.info(f"ğŸ“‹ Combined name history: {len(name_history_list)} entries")
                
                logger.info(f"ğŸ“Š Processed {processed_files} files for user {user_id}")
                logger.info(f"ğŸ“Š Total unique messages: {len(merged_data['messages'])}")
                logger.info(f"ğŸ“Š Total groups found: {len(merged_data['groups_info'])}")
                merged_data['total_files_merged'] = processed_files
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ
            current_time = datetime.now().strftime('%Y%m%d_%H%M%S')
            import uuid
            unique_id = str(uuid.uuid4())[:8]
            final_filename = f"final_{user_id}_{current_time}_{unique_id}.json"
            
            logger.info(f"âœ… Merged {len(merged_data.get('messages', []))} messages for user {user_id}")
            return True, merged_data, final_filename
            
        except Exception as e:
            logger.error(f"âŒ Error merging user JSON files: {e}")
            return False, None, None
    
    async def send_final_json(self, data: Dict[str, Any], filename: str) -> bool:
        """Ø§Ø±Ø³Ø§Ù„ ÙØ§ÛŒÙ„ JSON Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ù‡ Saved Messages"""
        try:
            # Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ JSON Ù…ÙˆÙ‚Øª
            temp_file_path = f"temp_{filename}"
            
            with open(temp_file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2, default=str)
            
            # Ø§Ø±Ø³Ø§Ù„ ÙØ§ÛŒÙ„ Ø¨Ù‡ Saved Messages
            await self.client.send_document(
                chat_id=self.target_chat_id,
                document=temp_file_path,
                caption=f"ğŸ“ Final JSON for user {data.get('user_id', 'unknown')}\nğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
            )
            
            # Ø­Ø°Ù ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª
            if os.path.exists(temp_file_path):
                os.remove(temp_file_path)
            
            logger.info(f"âœ… Final JSON sent: {filename}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error sending final JSON: {e}")
            return False 